1:HL["/2024/_next/static/css/224e84f1e9eeaa94.css","style",{"crossOrigin":""}]
0:["3UNR05-65EIbaBB_KTL80",[[["",{"children":["(website)",{"children":["poster",{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],"$L2",[[["$","link","0",{"rel":"stylesheet","href":"/2024/_next/static/css/224e84f1e9eeaa94.css","precedence":"next","crossOrigin":""}]],"$L3"]]]]
4:I[3994,["3994","static/chunks/3994-aefd8908e665ada6.js","3185","static/chunks/app/layout-9d3b4079ab523160.js"],""]
5:I[6954,[],""]
6:I[7264,[],""]
7:I[5827,["3190","static/chunks/ec3863c0-e603207d76f93494.js","6281","static/chunks/08ffe114-bc50350bf57134a7.js","1582","static/chunks/bc9c3264-fd195df4f0df8e0e.js","2306","static/chunks/39209d7c-6dc01663c56e9101.js","2420","static/chunks/9081a741-c035bf9254b49a25.js","5717","static/chunks/5717-27a80ee10bd46c59.js","1750","static/chunks/1750-b247d89b72bb50f7.js","1396","static/chunks/1396-21619ac464ca245d.js","8021","static/chunks/8021-3ba76b76550f3c7b.js","2439","static/chunks/2439-ff5f00e6120b5dd2.js","7714","static/chunks/7714-4d2a37a55859c888.js","2056","static/chunks/app/(website)/layout-395e810907199324.js"],""]
d:I[4104,["3190","static/chunks/ec3863c0-e603207d76f93494.js","6281","static/chunks/08ffe114-bc50350bf57134a7.js","1582","static/chunks/bc9c3264-fd195df4f0df8e0e.js","2306","static/chunks/39209d7c-6dc01663c56e9101.js","2420","static/chunks/9081a741-c035bf9254b49a25.js","5717","static/chunks/5717-27a80ee10bd46c59.js","1750","static/chunks/1750-b247d89b72bb50f7.js","1396","static/chunks/1396-21619ac464ca245d.js","8021","static/chunks/8021-3ba76b76550f3c7b.js","2439","static/chunks/2439-ff5f00e6120b5dd2.js","7714","static/chunks/7714-4d2a37a55859c888.js","2056","static/chunks/app/(website)/layout-395e810907199324.js"],""]
8:{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"}
9:{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"}
a:{"display":"inline-block"}
b:{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0}
2:[null,["$","html",null,{"lang":"zh-TW","children":[["$","head",null,{"children":[["$","link",null,{"rel":"icon","href":"/2024/favicon.png"}],["$","link",null,{"rel":"preconnect","href":"https://fonts.googleapis.com"}],["$","link",null,{"rel":"preconnect","href":"https://fonts.gstatic.com","crossOrigin":""}],["$","link",null,{"href":"https://fonts.googleapis.com/css2?family=Lato:wght@400;700&family=Noto+Sans+TC:wght@400;700&family=Rubik:wght@500;700&display=swap","rel":"stylesheet"}],["$","$L4",null,{"id":"gtm","strategy":"afterInteractive","dangerouslySetInnerHTML":{"__html":"(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':\n            new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],\n            j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=\n            'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);\n            })(window,document,'script','dataLayer','GTM-NPVBCDZ');"}}],["$","$L4",null,{"id":"pancake","strategy":"afterInteractive","dangerouslySetInnerHTML":{"__html":"console.log(\"%c美味的蓬蓬鬆餅都在這裡！%c https://pancake.tw \", \"background-color: #13AA13; color: white; padding: 5px;\", \"background-color: #f2f2f2; color: white; padding: 5px;\");"}}]]}],["$","body",null,{"className":"overflow-x-hidden font-sans leading-8","children":["$","$L5",null,{"parallelRouterKey":"children","segmentPath":["children"],"loading":"$undefined","loadingStyles":"$undefined","loadingScripts":"$undefined","hasLoading":false,"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L6",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":"404"}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],"notFoundStyles":[],"childProp":{"current":[null,["$","div",null,{"className":"flex min-h-screen flex-col bg-[#F8F3E8]","children":[["$","head",null,{"children":["$","meta",null,{"name":"theme-color","content":"#F8F3E8"}]}],["$","$L7",null,{}],["$","div",null,{"className":"grow","children":["$","$L5",null,{"parallelRouterKey":"children","segmentPath":["children","(website)","children"],"loading":"$undefined","loadingStyles":"$undefined","loadingScripts":"$undefined","hasLoading":false,"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L6",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":"$8","children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":"$9","children":"404"}],["$","div",null,{"style":"$a","children":["$","h2",null,{"style":"$b","children":"This page could not be found."}]}]]}]}]],"notFoundStyles":[],"childProp":{"current":["$","$L5",null,{"parallelRouterKey":"children","segmentPath":["children","(website)","children","poster","children"],"loading":"$undefined","loadingStyles":"$undefined","loadingScripts":"$undefined","hasLoading":false,"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L6",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","childProp":{"current":["$Lc",["$","div",null,{"className":"container","children":[["$","div",null,{"className":"mb-4 text-2xl font-bold md:text-4xl","id":"page-title","children":"靜態海報展"}],["$","div",null,{"className":"flex flex-col gap-4 md:gap-8","children":[["$","div","0",{"className":"relative scroll-m-[100px] items-center overflow-hidden rounded-2xl bg-white p-4 shadow-md","id":"poster-0","children":["$","div",null,{"className":"flex flex-col lg:flex-row","children":[["$","div",null,{"className":"w-full shrink-0 lg:w-[400px]","children":["$","img",null,{"src":"/2024/poster/我預判你的預判 中學生與AI圍棋理論的對戰歷程.webp","alt":"我預判你的預判：中學生與 AI 圍棋理論的對戰歷程","className":"aspect-[1/1.414] w-full rounded-xl"}]}],["$","div",null,{"className":"flex flex-col rounded-xl max-lg:py-2 lg:px-4","children":[["$","div",null,{"className":"text-xl font-bold text-[#385aac] lg:text-2xl","children":"我預判你的預判：中學生與 AI 圍棋理論的對戰歷程"}],["$","div",null,{"className":"porse mt-1 break-all max-lg:text-sm","children":["$","p","p-0",{"children":"我的研究動機源於對電腦圍棋的憧憬，目的在於分享我從不懂 AI 到逐步開發出我自己的圍棋機器人 SigmaGo 的過程，希望能激勵同為中學生的夢想家。在研究過程中，我從《深度學習與圍棋》和 AlphaGo 論文中學習到了蒙特卡洛樹搜索法、Policy 網路和 Value 網路等關鍵概念。我用 Pytorch 訓練卷積神經網路，並從開源網站獲得大量九路圍棋棋譜以加強訓練。面對 SigmaGo 無法完全理解圍棋規則的挑戰，我引入了 Gym_Go 模組來確保合法棋步的選擇，並透過 Go Text Protocol 與 Sabaki 介面連接，測試 SigmaGo 的實際棋力。在與不同棋力的 GNUGo 對戰中，我發現 SigmaGo 的勝率隨對手棋力提升而下降，其棋力約等於 GNUGo 的第四等級。未來，我計劃引入更多高級技術如 MCTS 法、Value 網路和強化學習，以提升 SigmaGo 的能力。"}]}],["$","div",null,{"className":"my-4 h-[2px] rounded-full bg-current opacity-5"}],["$","div",null,{"className":"flex items-center gap-2 text-lg","children":[["$","div",null,{"className":"flex shrink-0","style":{"gap":"-8px"},"children":[["$","img","0",{"src":"/2024/poster/我預判你的預判 中學生與AI圍棋理論的對戰歷程_1.webp","alt":"我預判你的預判：中學生與 AI 圍棋理論的對戰歷程","className":"h-8 w-8 rounded-full border border-white object-cover shadow-sm"}]]}],"tudo"]}],["$","div",null,{"className":"porse mt-1 break-all max-lg:text-sm","children":["$","p","p-0",{"children":"我是一名 16 歲的高中生，對於軟硬軔三位一體的電子世界充滿了好奇心。曾於在 Dimwave Tech 實習，在裡面專注於學習硬體的開發。我還在 CKCSC 學習 C++ 和演算法，搭建起了程式設計基礎。我同時也對資訊安全和人工智慧感興趣，致力於創建對這個社會、對國家、對自己有價值的項目。未來目標是在科技業留下自己的印記。我目前的目標是學習資料科學和數學、量子電腦、資訊安全和深度學習。"}]}],["$","div",null,{"className":"my-4 flex-1"}],["$","div",null,{"className":"flex justify-end gap-4","children":["$","a",null,{"href":"https://sitcon.org/2024/poster/我預判你的預判 中學生與AI圍棋理論的對戰歷程.pdf","className":"flex items-center justify-center gap-2 break-keep rounded-full bg-[#385AAC] p-4 py-1.5 text-xl font-bold text-[#F8F3E8] shadow-[0px_6px_6px_0px_#5D7DDB4D] hover:bg-[#304e96] active:bg-[#263d75] md:text-lg","download":"我預判你的預判 中學生與AI圍棋理論的對戰歷程.pdf","children":[["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 512 512","children":["$undefined",[["$","path","0",{"d":"M472.7 189.5c-13.26-8.43-29.83-14.56-48.08-17.93A16 16 0 01412 159.28c-7.86-34.51-24.6-64.13-49.15-86.58C334.15 46.45 296.21 32 256 32c-35.35 0-68 11.08-94.37 32a150.13 150.13 0 00-41.95 52.83A16.05 16.05 0 01108 125.8c-27.13 4.9-50.53 14.68-68.41 28.7C13.7 174.83 0 203.56 0 237.6 0 305 55.93 352 136 352h104V224.45c0-8.61 6.62-16 15.23-16.43A16 16 0 01272 224v128h124c72.64 0 116-34.24 116-91.6 0-30.05-13.59-54.57-39.3-70.9zM240 425.42l-36.7-36.64a16 16 0 00-22.6 22.65l64 63.89a16 16 0 0022.6 0l64-63.89a16 16 0 00-22.6-22.65L272 425.42V352h-32z","children":"$undefined"}]]],"className":"$undefined","style":{"color":"$undefined"},"height":"1em","width":"1em","xmlns":"http://www.w3.org/2000/svg"}],"下載海報"]}]}]]}]]}]}],["$","div","1",{"className":"relative scroll-m-[100px] items-center overflow-hidden rounded-2xl bg-white p-4 shadow-md","id":"poster-1","children":["$","div",null,{"className":"flex flex-col lg:flex-row","children":[["$","div",null,{"className":"w-full shrink-0 lg:w-[400px]","children":["$","img",null,{"src":"/2024/poster/演算法家家酒.webp","alt":"演算法家家酒","className":"aspect-[1/1.414] w-full rounded-xl"}]}],["$","div",null,{"className":"flex flex-col rounded-xl max-lg:py-2 lg:px-4","children":[["$","div",null,{"className":"text-xl font-bold text-[#385aac] lg:text-2xl","children":"演算法家家酒"}],["$","div",null,{"className":"porse mt-1 break-all max-lg:text-sm","children":["$","p","p-0",{"children":"設計一個「遊戲式演算法學習系統」，採用可觸摸（Tangle）的 LEGO 積木來編排關卡以及體現（Embodied）操作的學習方式。此學習方式，很像兒童的「家家酒」角色扮演遊戲，玩家透過對話、想像和創造的過程獲得趣味。同樣的，玩家在此系統中，可以扮演出題老師透過 LEGO 編輯演算法關卡，也可以扮演答題學生透過操作玩具來實現演算法步驟，是一個充滿人際互動與教育意義的遊戲。"}]}],["$","div",null,{"className":"my-4 h-[2px] rounded-full bg-current opacity-5"}],["$","div",null,{"className":"flex items-center gap-2 text-lg","children":[["$","div",null,{"className":"flex shrink-0","style":{"gap":"-8px"},"children":[["$","img","0",{"src":"/2024/poster/演算法家家酒_1.webp","alt":"演算法家家酒","className":"h-8 w-8 rounded-full border border-white object-cover shadow-sm"}],["$","img","1",{"src":"/2024/poster/演算法家家酒_2.webp","alt":"演算法家家酒","className":"-ml-1 h-8 w-8 rounded-full border border-white object-cover shadow-sm"}],["$","img","2",{"src":"/2024/poster/演算法家家酒_3.webp","alt":"演算法家家酒","className":"-ml-1 h-8 w-8 rounded-full border border-white object-cover shadow-sm"}]]}],"王昱智 / 王子杰 / 白雋揚"]}],["$","div",null,{"className":"porse mt-1 break-all max-lg:text-sm","children":["$","p","p-0",{"children":"目前就讀於逢甲大學資訊工程學系四年級生"}]}],["$","div",null,{"className":"my-4 flex-1"}],["$","div",null,{"className":"flex justify-end gap-4","children":["$","a",null,{"href":"https://sitcon.org/2024/poster/演算法家家酒.pdf","className":"flex items-center justify-center gap-2 break-keep rounded-full bg-[#385AAC] p-4 py-1.5 text-xl font-bold text-[#F8F3E8] shadow-[0px_6px_6px_0px_#5D7DDB4D] hover:bg-[#304e96] active:bg-[#263d75] md:text-lg","download":"演算法家家酒.pdf","children":[["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 512 512","children":["$undefined",[["$","path","0",{"d":"M472.7 189.5c-13.26-8.43-29.83-14.56-48.08-17.93A16 16 0 01412 159.28c-7.86-34.51-24.6-64.13-49.15-86.58C334.15 46.45 296.21 32 256 32c-35.35 0-68 11.08-94.37 32a150.13 150.13 0 00-41.95 52.83A16.05 16.05 0 01108 125.8c-27.13 4.9-50.53 14.68-68.41 28.7C13.7 174.83 0 203.56 0 237.6 0 305 55.93 352 136 352h104V224.45c0-8.61 6.62-16 15.23-16.43A16 16 0 01272 224v128h124c72.64 0 116-34.24 116-91.6 0-30.05-13.59-54.57-39.3-70.9zM240 425.42l-36.7-36.64a16 16 0 00-22.6 22.65l64 63.89a16 16 0 0022.6 0l64-63.89a16 16 0 00-22.6-22.65L272 425.42V352h-32z","children":"$undefined"}]]],"className":"$undefined","style":{"color":"$undefined"},"height":"1em","width":"1em","xmlns":"http://www.w3.org/2000/svg"}],"下載海報"]}]}]]}]]}]}],["$","div","2",{"className":"relative scroll-m-[100px] items-center overflow-hidden rounded-2xl bg-white p-4 shadow-md","id":"poster-2","children":["$","div",null,{"className":"flex flex-col lg:flex-row","children":[["$","div",null,{"className":"w-full shrink-0 lg:w-[400px]","children":["$","img",null,{"src":"/2024/poster/Taiwan-LLM Tutor Large Language Models.webp","alt":"Taiwan-LLM Tutor: Large Language Models","className":"aspect-[1/1.414] w-full rounded-xl"}]}],["$","div",null,{"className":"flex flex-col rounded-xl max-lg:py-2 lg:px-4","children":[["$","div",null,{"className":"text-xl font-bold text-[#385aac] lg:text-2xl","children":"Taiwan-LLM Tutor: Large Language Models"}],["$","div",null,{"className":"porse mt-1 break-all max-lg:text-sm","children":["$","p","p-0",{"children":["在本專案中，我們想建立 AI tutor 回答高中生社會科的問題。我們整理近 30 年的學測社會科考題與社會科題庫，利用 instruction tuning fine tune TAIWAN-LLM-7B 模型，並採用 LoftQ、Lion Optimizer 等方法提升模型效能，最後比較模型於社會三科中的表現。我們的專案公開至 ",["$","a","a-0",{"href":"https://github.com/jwliao1209/TWLLM-Tutor","children":"https://github.com/jwliao1209/TWLLM-Tutor"}],"。"]}]}],["$","div",null,{"className":"my-4 h-[2px] rounded-full bg-current opacity-5"}],["$","div",null,{"className":"flex items-center gap-2 text-lg","children":[["$","div",null,{"className":"flex shrink-0","style":{"gap":"-8px"},"children":[["$","img","0",{"src":"/2024/poster/Taiwan-LLM Tutor Large Language Models_1.webp","alt":"Taiwan-LLM Tutor: Large Language Models","className":"h-8 w-8 rounded-full border border-white object-cover shadow-sm"}]]}],"Jiawei"]}],["$","div",null,{"className":"porse mt-1 break-all max-lg:text-sm","children":[["$","p","p-0",{"children":"我是 Jiawei，現就讀台大資工博士二年級，並於台大資料分析與決策社擔任課程長，熱愛資料、AI、數學、教育。原本從事計算數學與電腦視覺相關研究，近期跨領域至 LLM 相關應用，渴望做出一個 AI 家教幫助偏鄉孩童與弱勢族群，目前我們還在努力的路上，成果到達及格的邊緣。"}],"\n",["$","p","p-1",{"children":["Linkedln: ",["$","a","a-0",{"href":"https://www.linkedin.com/in/jwliao1209/","children":"https://www.linkedin.com/in/jwliao1209/"}]]}],"\n",["$","p","p-2",{"children":["GitHub: ",["$","a","a-0",{"href":"https://github.com/jwliao1209","children":"https://github.com/jwliao1209"}]]}]]}],["$","div",null,{"className":"my-4 flex-1"}],["$","div",null,{"className":"flex justify-end gap-4","children":["$","a",null,{"href":"https://sitcon.org/2024/poster/Taiwan-LLM Tutor Large Language Models.pdf","className":"flex items-center justify-center gap-2 break-keep rounded-full bg-[#385AAC] p-4 py-1.5 text-xl font-bold text-[#F8F3E8] shadow-[0px_6px_6px_0px_#5D7DDB4D] hover:bg-[#304e96] active:bg-[#263d75] md:text-lg","download":"Taiwan-LLM Tutor Large Language Models.pdf","children":[["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 512 512","children":["$undefined",[["$","path","0",{"d":"M472.7 189.5c-13.26-8.43-29.83-14.56-48.08-17.93A16 16 0 01412 159.28c-7.86-34.51-24.6-64.13-49.15-86.58C334.15 46.45 296.21 32 256 32c-35.35 0-68 11.08-94.37 32a150.13 150.13 0 00-41.95 52.83A16.05 16.05 0 01108 125.8c-27.13 4.9-50.53 14.68-68.41 28.7C13.7 174.83 0 203.56 0 237.6 0 305 55.93 352 136 352h104V224.45c0-8.61 6.62-16 15.23-16.43A16 16 0 01272 224v128h124c72.64 0 116-34.24 116-91.6 0-30.05-13.59-54.57-39.3-70.9zM240 425.42l-36.7-36.64a16 16 0 00-22.6 22.65l64 63.89a16 16 0 0022.6 0l64-63.89a16 16 0 00-22.6-22.65L272 425.42V352h-32z","children":"$undefined"}]]],"className":"$undefined","style":{"color":"$undefined"},"height":"1em","width":"1em","xmlns":"http://www.w3.org/2000/svg"}],"下載海報"]}]}]]}]]}]}],["$","div","3",{"className":"relative scroll-m-[100px] items-center overflow-hidden rounded-2xl bg-white p-4 shadow-md","id":"poster-3","children":["$","div",null,{"className":"flex flex-col lg:flex-row","children":[["$","div",null,{"className":"w-full shrink-0 lg:w-[400px]","children":["$","img",null,{"src":"/2024/poster/摸透語言模型的習性 LLM 會偏袒什麼樣的文章.webp","alt":"摸透語言模型的習性：LLM 會偏袒什麼樣的文章？","className":"aspect-[1/1.414] w-full rounded-xl"}]}],["$","div",null,{"className":"flex flex-col rounded-xl max-lg:py-2 lg:px-4","children":[["$","div",null,{"className":"text-xl font-bold text-[#385aac] lg:text-2xl","children":"摸透語言模型的習性：LLM 會偏袒什麼樣的文章？"}],["$","div",null,{"className":"porse mt-1 break-all max-lg:text-sm","children":["$","p","p-0",{"children":"隨著 ChatGPT 等語言模型的使用快速成長，可以預期未來網路上將充斥著大型自然語言模型（Large Language Models，簡稱 LLM）直接生成的文章。我們不禁好奇，這些 LLM 會不會偏好自己生成的文章呢？更明確地說，給定 LLM 數篇可用以回答問題的參考文章時，它們是否更傾向以自己生成的內容作為回答依據，造成 LLM 的回答不夠中立，甚至被自己的文章誤導、產生幻覺呢？在這場演講中，將以嚴謹的實驗討論 ChatGPT 與 Llama 2 這兩個 LLM 對「人類撰寫的文章」、「自己生成的文章」、「其他 LLM 生成的文章」分別的偏好程度。"}]}],["$","div",null,{"className":"my-4 h-[2px] rounded-full bg-current opacity-5"}],["$","div",null,{"className":"flex items-center gap-2 text-lg","children":[["$","div",null,{"className":"flex shrink-0","style":{"gap":"-8px"},"children":[["$","img","0",{"src":"/2024/poster/摸透語言模型的習性 LLM 會偏袒什麼樣的文章_1.webp","alt":"摸透語言模型的習性：LLM 會偏袒什麼樣的文章？","className":"h-8 w-8 rounded-full border border-white object-cover shadow-sm"}]]}],"陳妍姍"]}],["$","div",null,{"className":"porse mt-1 break-all max-lg:text-sm","children":["$","p","p-0",{"children":"資工系大三學生，對 NLP、影像、演算法、神經科學、經濟學、心理學都有興趣，什麼都學一點，但什麼都沒有很厲害，還在努力探索未來的方向當中。目前在奧義智慧科技當 ML research intern。"}]}],["$","div",null,{"className":"my-4 flex-1"}],["$","div",null,{"className":"flex justify-end gap-4","children":["$","a",null,{"href":"https://sitcon.org/2024/poster/摸透語言模型的習性 LLM 會偏袒什麼樣的文章.pdf","className":"flex items-center justify-center gap-2 break-keep rounded-full bg-[#385AAC] p-4 py-1.5 text-xl font-bold text-[#F8F3E8] shadow-[0px_6px_6px_0px_#5D7DDB4D] hover:bg-[#304e96] active:bg-[#263d75] md:text-lg","download":"摸透語言模型的習性 LLM 會偏袒什麼樣的文章.pdf","children":[["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 512 512","children":["$undefined",[["$","path","0",{"d":"M472.7 189.5c-13.26-8.43-29.83-14.56-48.08-17.93A16 16 0 01412 159.28c-7.86-34.51-24.6-64.13-49.15-86.58C334.15 46.45 296.21 32 256 32c-35.35 0-68 11.08-94.37 32a150.13 150.13 0 00-41.95 52.83A16.05 16.05 0 01108 125.8c-27.13 4.9-50.53 14.68-68.41 28.7C13.7 174.83 0 203.56 0 237.6 0 305 55.93 352 136 352h104V224.45c0-8.61 6.62-16 15.23-16.43A16 16 0 01272 224v128h124c72.64 0 116-34.24 116-91.6 0-30.05-13.59-54.57-39.3-70.9zM240 425.42l-36.7-36.64a16 16 0 00-22.6 22.65l64 63.89a16 16 0 0022.6 0l64-63.89a16 16 0 00-22.6-22.65L272 425.42V352h-32z","children":"$undefined"}]]],"className":"$undefined","style":{"color":"$undefined"},"height":"1em","width":"1em","xmlns":"http://www.w3.org/2000/svg"}],"下載海報"]}]}]]}]]}]}],["$","div","4",{"className":"relative scroll-m-[100px] items-center overflow-hidden rounded-2xl bg-white p-4 shadow-md","id":"poster-4","children":["$","div",null,{"className":"flex flex-col lg:flex-row","children":[["$","div",null,{"className":"w-full shrink-0 lg:w-[400px]","children":["$","img",null,{"src":"/2024/poster/Enhanced Real-World Video Question-Answering A Selective-Based Approach.webp","alt":"Enhanced Real-World Video Question-Answering :A Selective-Based Approach","className":"aspect-[1/1.414] w-full rounded-xl"}]}],["$","div",null,{"className":"flex flex-col rounded-xl max-lg:py-2 lg:px-4","children":[["$","div",null,{"className":"text-xl font-bold text-[#385aac] lg:text-2xl","children":"Enhanced Real-World Video Question-Answering :A Selective-Based Approach"}],["$","div",null,{"className":"porse mt-1 break-all max-lg:text-sm","children":[["$","p","p-0",{"children":"In this poster, we address video question-answering (VQA) challenges within the STAR dataset [1]. We present a modified version of the Flipped VQA 7B model [2], enhancing it by implementing a trainable frame selector and utilizing Llama-adapter [3] for fine-tuning. Also, we conduct an in-depth analysis of failed predictions and fine-tune hyper-parameters for improved accuracy."}],"\n",["$","ul","ul-0",{"children":["\n",["$","li","li-0",{"children":"[1] Bo Wu, et el. STAR: A Benchmark for Situated Reasoning in Real-World Videos. In NeurIPS 2021."}],"\n",["$","li","li-1",{"children":"[2] Dohwan Ko, et el. Large Language Models are Temporal and Causal Reasoners for Video Question Answering. In EMNLP 2023."}],"\n",["$","li","li-2",{"children":"[3] R Zhang, et al. LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention. arXiv:2303.16199, 2023."}],"\n"]}]]}],["$","div",null,{"className":"my-4 h-[2px] rounded-full bg-current opacity-5"}],["$","div",null,{"className":"flex items-center gap-2 text-lg","children":[["$","div",null,{"className":"flex shrink-0","style":{"gap":"-8px"},"children":[["$","img","0",{"src":"/2024/poster/Enhanced Real-World Video Question-Answering A Selective-Based Approach_1.webp","alt":"Enhanced Real-World Video Question-Answering :A Selective-Based Approach","className":"h-8 w-8 rounded-full border border-white object-cover shadow-sm"}]]}],"恩恩"]}],["$","div",null,{"className":"porse mt-1 break-all max-lg:text-sm","children":["$","p","p-0",{"children":"As a mathematics student with a strong passion for artificial intelligence, I enjoy leveraging my mathematical knowledge to solve real‐world computer vision tasks through AI integration. For example, I have recently developed a real‐time automatic system for tracking and analyzing basketball matches using computer vision, deep learning models, and various mathematical techniques. As hobbies, I have served as the team leader in three AI Cup competitions, each with commendable results."}]}],["$","div",null,{"className":"my-4 flex-1"}],["$","div",null,{"className":"flex justify-end gap-4","children":["$","a",null,{"href":"https://sitcon.org/2024/poster/Enhanced Real-World Video Question-Answering A Selective-Based Approach.pdf","className":"flex items-center justify-center gap-2 break-keep rounded-full bg-[#385AAC] p-4 py-1.5 text-xl font-bold text-[#F8F3E8] shadow-[0px_6px_6px_0px_#5D7DDB4D] hover:bg-[#304e96] active:bg-[#263d75] md:text-lg","download":"Enhanced Real-World Video Question-Answering A Selective-Based Approach.pdf","children":[["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 512 512","children":["$undefined",[["$","path","0",{"d":"M472.7 189.5c-13.26-8.43-29.83-14.56-48.08-17.93A16 16 0 01412 159.28c-7.86-34.51-24.6-64.13-49.15-86.58C334.15 46.45 296.21 32 256 32c-35.35 0-68 11.08-94.37 32a150.13 150.13 0 00-41.95 52.83A16.05 16.05 0 01108 125.8c-27.13 4.9-50.53 14.68-68.41 28.7C13.7 174.83 0 203.56 0 237.6 0 305 55.93 352 136 352h104V224.45c0-8.61 6.62-16 15.23-16.43A16 16 0 01272 224v128h124c72.64 0 116-34.24 116-91.6 0-30.05-13.59-54.57-39.3-70.9zM240 425.42l-36.7-36.64a16 16 0 00-22.6 22.65l64 63.89a16 16 0 0022.6 0l64-63.89a16 16 0 00-22.6-22.65L272 425.42V352h-32z","children":"$undefined"}]]],"className":"$undefined","style":{"color":"$undefined"},"height":"1em","width":"1em","xmlns":"http://www.w3.org/2000/svg"}],"下載海報"]}]}]]}]]}]}],["$","div","5",{"className":"relative scroll-m-[100px] items-center overflow-hidden rounded-2xl bg-white p-4 shadow-md","id":"poster-5","children":["$","div",null,{"className":"flex flex-col lg:flex-row","children":[["$","div",null,{"className":"w-full shrink-0 lg:w-[400px]","children":["$","img",null,{"src":"/2024/poster/利用 Transformer 判斷人臉健康狀況系統.webp","alt":"利用 Transformer 判斷人臉健康狀況系統","className":"aspect-[1/1.414] w-full rounded-xl"}]}],["$","div",null,{"className":"flex flex-col rounded-xl max-lg:py-2 lg:px-4","children":[["$","div",null,{"className":"text-xl font-bold text-[#385aac] lg:text-2xl","children":"利用 Transformer 判斷人臉健康狀況系統"}],["$","div",null,{"className":"porse mt-1 break-all max-lg:text-sm","children":["$","p","p-0",{"children":"人臉是人類獨特的身份標誌，提供年齡、情緒和健康等資訊。人臉與健康息息相關，通過觀察臉部，如眼睛、皮膚，可以初步推斷是否有健康問題，對於病症的及時治療和改善相當重要。本研究使用 Dlib 函式庫進行人臉偵測，以及使用 Vision Transformer 模型訓練，此模型是基於多頭自注意力機制（Multi-Head Self-Attention）的圖像式深度學習模型，利用自注意力機制提升模型訓練速度，及其可擴展性，被廣泛應用於電腦視覺領域，因此本研究使用 Vision Transformer 模型，識別人臉的健康與帶有病徵的狀況。訓練模型使用的公開資料集來自 Kaggle、Roboflow，以及使用 Google 、 Microsoft Bing 等搜尋引擎蒐集圖像。此研究使用 5 種病徵及無病徵，共 6 種類別，作為圖像資料集的類別來訓練 Vision Transformer 模型，得到的 Accuracy 為 80.24%， Loss 值為 0.9988。"}]}],["$","div",null,{"className":"my-4 h-[2px] rounded-full bg-current opacity-5"}],["$","div",null,{"className":"flex items-center gap-2 text-lg","children":[["$","div",null,{"className":"flex shrink-0","style":{"gap":"-8px"},"children":[["$","img","0",{"src":"/2024/poster/利用 Transformer 判斷人臉健康狀況系統_1.webp","alt":"利用 Transformer 判斷人臉健康狀況系統","className":"h-8 w-8 rounded-full border border-white object-cover shadow-sm"}]]}],"Lily"]}],["$","div",null,{"className":"porse mt-1 break-all max-lg:text-sm","children":["$","p","p-0",{"children":"目前資工系四年級，資工越學越有興趣。"}]}],["$","div",null,{"className":"my-4 flex-1"}],["$","div",null,{"className":"flex justify-end gap-4","children":["$","a",null,{"href":"https://sitcon.org/2024/poster/利用 Transformer 判斷人臉健康狀況系統.pdf","className":"flex items-center justify-center gap-2 break-keep rounded-full bg-[#385AAC] p-4 py-1.5 text-xl font-bold text-[#F8F3E8] shadow-[0px_6px_6px_0px_#5D7DDB4D] hover:bg-[#304e96] active:bg-[#263d75] md:text-lg","download":"利用 Transformer 判斷人臉健康狀況系統.pdf","children":[["$","svg",null,{"stroke":"currentColor","fill":"currentColor","strokeWidth":"0","viewBox":"0 0 512 512","children":["$undefined",[["$","path","0",{"d":"M472.7 189.5c-13.26-8.43-29.83-14.56-48.08-17.93A16 16 0 01412 159.28c-7.86-34.51-24.6-64.13-49.15-86.58C334.15 46.45 296.21 32 256 32c-35.35 0-68 11.08-94.37 32a150.13 150.13 0 00-41.95 52.83A16.05 16.05 0 01108 125.8c-27.13 4.9-50.53 14.68-68.41 28.7C13.7 174.83 0 203.56 0 237.6 0 305 55.93 352 136 352h104V224.45c0-8.61 6.62-16 15.23-16.43A16 16 0 01272 224v128h124c72.64 0 116-34.24 116-91.6 0-30.05-13.59-54.57-39.3-70.9zM240 425.42l-36.7-36.64a16 16 0 00-22.6 22.65l64 63.89a16 16 0 0022.6 0l64-63.89a16 16 0 00-22.6-22.65L272 425.42V352h-32z","children":"$undefined"}]]],"className":"$undefined","style":{"color":"$undefined"},"height":"1em","width":"1em","xmlns":"http://www.w3.org/2000/svg"}],"下載海報"]}]}]]}]]}]}]]}]]}],null],"segment":"__PAGE__"},"styles":null}],"segment":"poster"},"styles":null}]}],["$","$Ld",null,{}]]}],null],"segment":"(website)"},"styles":null}]}]]}],null]
3:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"SITCON 2024"}],["$","meta","3",{"name":"description","content":"學生計算機年會（Students’ Information Technology Conference）自 2012 年發起，以學生為本、由學生自發舉辦，長期投身學生資訊教育與推廣開源精神，鼓勵學生們成為實踐者，貢獻程式碼、打造並部署服務、透過實際行動推動專案，最後將這些結晶分享出去，讓更多人能關注你認為重要的議題，打造更緊密的社群。"}],["$","meta","4",{"name":"author","content":"SITCON"}],["$","meta","5",{"name":"keywords","content":"SITCON, SITCON 2024"}],["$","meta","6",{"property":"og:title","content":"SITCON 2024"}],["$","meta","7",{"property":"og:description","content":"學生計算機年會（Students’ Information Technology Conference）自 2012 年發起，以學生為本、由學生自發舉辦，長期投身學生資訊教育與推廣開源精神，鼓勵學生們成為實踐者，貢獻程式碼、打造並部署服務、透過實際行動推動專案，最後將這些結晶分享出去，讓更多人能關注你認為重要的議題，打造更緊密的社群。"}],["$","meta","8",{"property":"og:url","content":"https://sitcon.org/2024/"}],["$","meta","9",{"property":"og:site_name","content":"SITCON"}],["$","meta","10",{"property":"og:locale","content":"zh_TW"}],["$","meta","11",{"property":"og:image","content":"https://sitcon.org/2024/og.jpg"}],["$","meta","12",{"property":"og:type","content":"website"}],["$","meta","13",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","14",{"name":"twitter:site","content":"@sitcontw"}],["$","meta","15",{"name":"twitter:creator","content":"@sitcontw"}],["$","meta","16",{"name":"twitter:title","content":"SITCON 2024"}],["$","meta","17",{"name":"twitter:description","content":"學生計算機年會（Students’ Information Technology Conference）自 2012 年發起，以學生為本、由學生自發舉辦，長期投身學生資訊教育與推廣開源精神，鼓勵學生們成為實踐者，貢獻程式碼、打造並部署服務、透過實際行動推動專案，最後將這些結晶分享出去，讓更多人能關注你認為重要的議題，打造更緊密的社群。"}],["$","meta","18",{"name":"twitter:image","content":"https://sitcon.org/2024/og.jpg"}]]
c:null
